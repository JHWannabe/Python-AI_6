{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c746d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa8567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Image CLASS-ID SPECIES BREED ID\n",
    "#ID: 1:37 Class ids\n",
    "#SPECIES: 1:Cat 2:Dog\n",
    "#BREED ID: 1-25:Cat 1:12:Dog\n",
    "#All images with 1st letter as captial are cat images\n",
    "#images with small first letter are dog images\n",
    "csv_path = 'data/kfolds.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "np.unique(df['id'])\n",
    "\n",
    "value_counts = df['id'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(value_counts)), value_counts.values)\n",
    "plt.xticks(range(len(value_counts)), value_counts.index.values)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c87a0e",
   "metadata": {},
   "source": [
    "* binary_crossentropy : binary 다중 분류 손실함수, label들이 독립적일 때 사용\n",
    "* categorical_crossentropy : 다중 분류 손실함수, 출력값이 one-hot encoding된 결과로 나옴, 각 샘플이 정확히 하나의 클래스에 속하는 경우 사용\n",
    "* sparse_categorical_crossentropy : 다중 분류 손실함수, one-hot encoding을 하지 않고 정수 형태로 넣어줌, 한 샘플에 여러 클래스가 있거나 label이 soft 확률일 경우 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f85e681",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, 1280)             4049571   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,050,852\n",
      "Trainable params: 4,008,829\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\python\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def get_model(input_shape):\n",
    "    inputs = keras.Input(input_shape)\n",
    "    base_model = EfficientNetB0(\n",
    "        input_shape = input_shape,\n",
    "        weights = 'imagenet',\n",
    "        include_top = False,\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    x= base_model(inputs)\n",
    "    output = layers.Dense(1, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "model =get_model(input_shape)\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bff8df5",
   "metadata": {},
   "source": [
    "* softmax\n",
    "- 출력은 0 ~ 1 사이의 실수\n",
    "- 출력을 확률로 해석할 수 있음\n",
    "- 출력의 총합은 1임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8026e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self, size, mode='train'):\n",
    "        if mode == 'train':\n",
    "            self.transform = A.Compose([\n",
    "                # 수평\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                # 이동, 크기, 회전을 설정\n",
    "                A.ShiftScaleRotate(\n",
    "                    p=0.5,\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=15\n",
    "                ),\n",
    "                # 최대 8개의 구멍을 dropout 하게됨\n",
    "                A.CoarseDropout(\n",
    "                    p=0.5,\n",
    "                    max_holes=8,\n",
    "                    max_height=int(0.1 * size),\n",
    "                    max_width=int(0.1 * size)\n",
    "                ),\n",
    "                A.RandomBrightnessContrast(p=0.2)\n",
    "            ])\n",
    "            \n",
    "    def __call__(self, **kwargs):\n",
    "        if self.transform:\n",
    "            augmented =self.transform(**kwargs)\n",
    "            img = augmented['image']\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f16b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, csv_path, fold, image_size, mode='train', shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "        \n",
    "        #### https://github.com/tensorflow/models/issues/3134\n",
    "        #### 파일 이슈 -> 삭제\n",
    "        invalid_filenames = [\n",
    "            'Egyptian_Mau_14',\n",
    "            'Egyptian_Mau_139',\n",
    "            'Egyptian_Mau_145',\n",
    "            'Egyptian_Mau_156',\n",
    "            'Egyptian_Mau_167',\n",
    "            'Egyptian_Mau_177',\n",
    "            'Egyptian_Mau_186',\n",
    "            'Egyptian_Mau_191',\n",
    "            'Abyssinian_5',\n",
    "            'Abyssinian_34',\n",
    "            'chihuahua_121',\n",
    "            'beagle_116'\n",
    "        ]\n",
    "        self.df = self.df[~self.df['file_name'].isin(invalid_filenames)]\n",
    "        self.transform = Augmentation(image_size, mode)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "            return math.ceil(len(self.df) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        strt = idx * self.batch_size\n",
    "        fin = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[strt:fin]\n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for _, r in data.iterrows():\n",
    "            file_name = r['file_name']\n",
    "            image = cv2.imread(f'data/images/{file_name}.jpg')\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "            \n",
    "            if self.mode == 'train':\n",
    "                image = image.astype('uint8')\n",
    "                image = self.transform(image=image)\n",
    "            \n",
    "            image = image.astype('float32')            \n",
    "            image = image / 255.\n",
    "        \n",
    "            label = int(r['id']) - 1\n",
    "            \n",
    "            batch_x.append(image)\n",
    "            batch_y.append(label)\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbda8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'data/kfolds.csv'\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    batch_size = 128,\n",
    "    csv_path = csv_path,\n",
    "    fold = 1,\n",
    "    image_size = 256,\n",
    "    mode = 'train',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "    batch_size = 128,\n",
    "    csv_path = csv_path,\n",
    "    fold = 1,\n",
    "    image_size = 256,\n",
    "    mode = 'val',\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "928a4666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/efficientnetb0/block4b_dwconv/depthwise' defined at (most recent call last):\n    File \"f:\\python\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"f:\\python\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"f:\\python\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"f:\\python\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"f:\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"f:\\python\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"f:\\python\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"f:\\python\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2958, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3003, in _run_cell\n      return runner(coro)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3229, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3524, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\jhjun\\AppData\\Local\\Temp\\ipykernel_8572\\1483182427.py\", line 5, in <module>\n      verbose=1\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 2772, in call\n      data_format=self.data_format)\n    File \"f:\\python\\lib\\site-packages\\keras\\backend.py\", line 5907, in depthwise_conv2d\n      data_format=tf_data_format)\nNode: 'model/efficientnetb0/block4b_dwconv/depthwise'\nOOM when allocating tensor with shape[128,16,16,480] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node model/efficientnetb0/block4b_dwconv/depthwise}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_19431]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8572\\1483182427.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;32mf:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\python\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/efficientnetb0/block4b_dwconv/depthwise' defined at (most recent call last):\n    File \"f:\\python\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"f:\\python\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"f:\\python\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"f:\\python\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"f:\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"f:\\python\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"f:\\python\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"f:\\python\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"f:\\python\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2958, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3003, in _run_cell\n      return runner(coro)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3229, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"f:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3524, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\jhjun\\AppData\\Local\\Temp\\ipykernel_8572\\1483182427.py\", line 5, in <module>\n      verbose=1\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"f:\\python\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 2772, in call\n      data_format=self.data_format)\n    File \"f:\\python\\lib\\site-packages\\keras\\backend.py\", line 5907, in depthwise_conv2d\n      data_format=tf_data_format)\nNode: 'model/efficientnetb0/block4b_dwconv/depthwise'\nOOM when allocating tensor with shape[128,16,16,480] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node model/efficientnetb0/block4b_dwconv/depthwise}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_19431]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469d87a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8572\\2678254738.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = history.history\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['accuracy'], label='train')\n",
    "plt.plot(history['val_accuracy'], label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58612f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
