{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc5bf33",
   "metadata": {},
   "source": [
    "# Unet 이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c3740",
   "metadata": {},
   "source": [
    "* U-Net : Convolutional Networks for Biomedical Image Segmentation 논문\n",
    "* Patch : 이미지 인식 단위\n",
    "* 기존의 Segmentation network들의 문제점을 해결(속도)\n",
    "* overlap의 비율이 적음\n",
    "* 3*3 convolution, 활성화 함수 relu, 2*2 max pooling -> 1/2 down sampling (Encode)\n",
    "* 2*2 up convolution, 3*3 convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc050f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef4b2825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.losses as losses\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    smooth = 0.\n",
    "    \n",
    "    # Flatten\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    \n",
    "    score = intersection / (union + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 0.\n",
    "    \n",
    "    # Flatten\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    score = (2. * intersection) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = 1.*losses.binary_crossentropy(y_true, y_pred) + 1.*dice_loss(y_true, y_pred)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5caa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "class Augmentation:\n",
    "    def __init__(self, size, mode='train'):\n",
    "        if mode == 'train':\n",
    "            self.transform = A.Compose([\n",
    "                # 수평\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                # 이동, 크기, 회전을 설정\n",
    "                A.ShiftScaleRotate(\n",
    "                    p=0.5,\n",
    "                    shift_limit=0.05,\n",
    "                    scale_limit=0.05,\n",
    "                    rotate_limit=15\n",
    "                ),\n",
    "                # 최대 8개의 구멍을 dropout 하게됨\n",
    "                A.CoarseDropout(\n",
    "                    p=0.5,\n",
    "                    max_holes=8,\n",
    "                    max_height=int(0.1 * size),\n",
    "                    max_width=int(0.1 * size)\n",
    "                ),\n",
    "                A.RandomBrightnessContrast(p=0.2)\n",
    "            ])\n",
    "    \n",
    "    def __call__(self, **kwargs): # {image=image, mask=mask}\n",
    "        if self.transform:\n",
    "            augmented = self.transform(**kwargs)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            return img, mask\n",
    "        \n",
    "        \n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, csv_path, fold, image_size, mode='train', shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "        \n",
    "        #### https://github.com/tensorflow/models/issues/3134\n",
    "        #### 파일 이슈 -> 삭제\n",
    "        invalid_filenames = [\n",
    "            'Egyptian_Mau_14',\n",
    "            'Egyptian_Mau_139',\n",
    "            'Egyptian_Mau_145',\n",
    "            'Egyptian_Mau_156',\n",
    "            'Egyptian_Mau_167',\n",
    "            'Egyptian_Mau_177',\n",
    "            'Egyptian_Mau_186',\n",
    "            'Egyptian_Mau_191',\n",
    "            'Abyssinian_5',\n",
    "            'Abyssinian_34',\n",
    "            'chihuahua_121',\n",
    "            'beagle_116'\n",
    "        ]\n",
    "        self.df = self.df[~self.df['file_name'].isin(invalid_filenames)]\n",
    "        self.transform = Augmentation(image_size, mode)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "            return math.ceil(len(self.df) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        strt = idx * self.batch_size\n",
    "        fin = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[strt:fin]\n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "        \n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for _, r in data.iterrows():\n",
    "            file_name = r['file_name']\n",
    "            image = cv2.imread(f'data/images/{file_name}.jpg')\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "            \n",
    "            mask = cv2.imread(f'data/annotations/trimaps/{file_name}.png', cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.resize(mask, (self.image_size, self.image_size))\n",
    "            mask[mask != 1] = 0\n",
    "            \n",
    "            if self.mode == 'train':\n",
    "#                 image = image.astype('uint8')\n",
    "                image, mask = self.transform(image=image, mask=mask)\n",
    "            \n",
    "            image = image.astype('float32')            \n",
    "            image = image / 255.\n",
    "            mask = mask.astype('float32')\n",
    "        \n",
    "            # label = int(r['id']) - 1\n",
    "            \n",
    "            batch_x.append(image)\n",
    "            batch_y.append(mask)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    \n",
    "csv_path = 'data/kfolds.csv'\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    batch_size = 128,\n",
    "    csv_path = csv_path,\n",
    "    fold = 1,\n",
    "    image_size = 128,\n",
    "    mode = 'train',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "    batch_size = 128,\n",
    "    csv_path = csv_path,\n",
    "    fold = 1,\n",
    "    image_size = 128,\n",
    "    mode = 'val',\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da9843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 128, 64  1728        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128, 128, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout2d (SpatialDrop  (None, 128, 128, 64  0          ['batch_normalization[0][0]']    \n",
      " out2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 64  36864       ['spatial_dropout2d[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 128)  73728       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (SpatialDr  (None, 64, 64, 128)  0          ['batch_normalization_2[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 128)  147456      ['spatial_dropout2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 128)  0          ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 256)  294912      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_2 (SpatialDr  (None, 32, 32, 256)  0          ['batch_normalization_4[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 256)  589824      ['spatial_dropout2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 256)  0          ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 16, 512)  1179648     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 16, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_3 (SpatialDr  (None, 16, 16, 512)  0          ['batch_normalization_6[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 512)  2359296     ['spatial_dropout2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 512)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 8, 8, 1024)   4718592     ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout2d_4 (SpatialDr  (None, 8, 8, 1024)  0           ['batch_normalization_8[0][0]']  \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 1024)   9437184     ['spatial_dropout2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 1024)  4096        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_transpose (Conv2DTransp  (None, 16, 16, 512)  2097664    ['batch_normalization_9[0][0]']  \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 512)  4718592     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 512)  2359296     ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 256)  524544     ['batch_normalization_11[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 256)  1179648     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 256)  589824      ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 128)  131200     ['batch_normalization_13[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 128)  294912      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 64, 64, 128)  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 128)  147456      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 64, 64, 128)  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 64  32832      ['batch_normalization_15[0][0]'] \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 64  73728       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 128, 128, 64  256        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 64  36864       ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 128, 128, 64  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 1)  65          ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,049,409\n",
      "Trainable params: 31,037,633\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/karolzak/keras-unet\n",
    "from keras_unet.models import custom_unet\n",
    "\n",
    "model = custom_unet(\n",
    "    input_shape = (128, 128, 3),\n",
    "    use_batch_norm = True,\n",
    "    upsample_mode = 'deconv',\n",
    "    dropout_type = 'spatial',\n",
    "    num_classes = 1,\n",
    "    filters = 64,\n",
    "    dropout = 0.2,\n",
    "    num_layers = 4,\n",
    "    output_activation='sigmoid'\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=bce_dice_loss, metrics=[iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d32b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function custom_unet in module keras_unet.models.custom_unet:\n",
      "\n",
      "custom_unet(input_shape, num_classes=1, activation='relu', use_batch_norm=True, upsample_mode='deconv', dropout=0.3, dropout_change_per_layer=0.0, dropout_type='spatial', use_dropout_on_upsampling=False, use_attention=False, filters=16, num_layers=4, output_activation='sigmoid')\n",
      "    Customisable UNet architecture (Ronneberger et al. 2015 [1]).\n",
      "    \n",
      "    Arguments:\n",
      "    input_shape: 3D Tensor of shape (x, y, num_channels)\n",
      "    \n",
      "    num_classes (int): Unique classes in the output mask. Should be set to 1 for binary segmentation\n",
      "    \n",
      "    activation (str): A keras.activations.Activation to use. ReLu by default.\n",
      "    \n",
      "    use_batch_norm (bool): Whether to use Batch Normalisation across the channel axis between convolutional layers\n",
      "    \n",
      "    upsample_mode (one of \"deconv\" or \"simple\"): Whether to use transposed convolutions or simple upsampling in the decoder part\n",
      "    \n",
      "    dropout (float between 0. and 1.): Amount of dropout after the initial convolutional block. Set to 0. to turn Dropout off\n",
      "    \n",
      "    dropout_change_per_layer (float between 0. and 1.): Factor to add to the Dropout after each convolutional block\n",
      "    \n",
      "    dropout_type (one of \"spatial\" or \"standard\"): Type of Dropout to apply. Spatial is recommended for CNNs [2]\n",
      "    \n",
      "    use_dropout_on_upsampling (bool): Whether to use dropout in the decoder part of the network\n",
      "    \n",
      "    use_attention (bool): Whether to use an attention dynamic when concatenating with the skip-connection, implemented as proposed by Oktay et al. [3]\n",
      "    \n",
      "    filters (int): Convolutional filters in the initial convolutional block. Will be doubled every block\n",
      "    \n",
      "    num_layers (int): Number of total layers in the encoder not including the bottleneck layer\n",
      "    \n",
      "    output_activation (str): A keras.activations.Activation to use. Sigmoid by default for binary segmentation\n",
      "    \n",
      "    Returns:\n",
      "    model (keras.models.Model): The built U-Net\n",
      "    \n",
      "    Raises:\n",
      "    ValueError: If dropout_type is not one of \"spatial\" or \"standard\"\n",
      "    \n",
      "    \n",
      "    [1]: https://arxiv.org/abs/1505.04597\n",
      "    [2]: https://arxiv.org/pdf/1411.4280.pdf\n",
      "    [3]: https://arxiv.org/abs/1804.03999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(custom_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422377a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data = valid_generator,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f6994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
